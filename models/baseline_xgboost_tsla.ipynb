{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8726c527",
   "metadata": {},
   "source": [
    "# A (Feeble) Baseline Model Using `xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ca9ae",
   "metadata": {},
   "source": [
    "# TLDR\n",
    "\n",
    "Baseline model using xgboost for interpolating the stock price of TSLA. More precisely, with respect to a pre-defined time period\n",
    "\n",
    "**RESULTS**\n",
    "- Metrics\n",
    "  - RMSE: 24.11\n",
    "  - MAE:  21.05\n",
    "- Most important features:\n",
    "  - avg_price_TSLA\n",
    "  - delta_price_AAPL\n",
    "  - volume_AAPL\n",
    "  - high_TSLA\n",
    "  - volume_MSFT\n",
    "  - price_ratio_AAPL\n",
    "  - close_TSLA_diff\n",
    "  - low_TSLA\n",
    "  - volume_NVDA\n",
    "  - close_TSLA_log_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58885f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional requirements\n",
    "\n",
    "# NOTE Move to requirements.txt if finally incorporated\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "\n",
    "# SPLIT_DATE = \"2023-01-01\"\n",
    "\n",
    "TARGET_TICKER = \"TSLA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "df = pd.read_csv(\"../data/processed_combined_data.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target extraction\n",
    "\n",
    "col_y = f\"close_{TARGET_TICKER}\"\n",
    "# cols_X = [f\"open_{TARGET_TICKER}\"] \n",
    "cols_X = [col for col in df.columns if col not in [col_y, \"date\"]] \n",
    "\n",
    "X = df[cols_X]\n",
    "y = df[col_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Train-Test Split Based on Pentiles\n",
    "\n",
    "n_pentile = len(df) // 5\n",
    "\n",
    "train_idxs_0 = np.arange(0, n_pentile * 2)\n",
    "train_idxs_1 = np.arange(n_pentile * 3, len(df))\n",
    "\n",
    "train_idxs = np.concatenate([train_idxs_0, train_idxs_1])\n",
    "\n",
    "test_idxs = np.arange(n_pentile * 2, n_pentile * 3)\n",
    "\n",
    "X_train = X.iloc[train_idxs]\n",
    "X_test = X.iloc[test_idxs]\n",
    "y_train = y.iloc[train_idxs]\n",
    "y_test = y.iloc[test_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "\n",
    "param_grid = {\n",
    "    # Tree depth\n",
    "    \"max_depth\": [3, 5, 7],  \n",
    "    # Learning rate (eta)\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],  \n",
    "    # Number of trees\n",
    "    \"n_estimators\": [50, 100, 200],  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e888260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup and Fit\n",
    "\n",
    "xgb_regressor = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_regressor,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22249649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Actual vs Predicted Values\n",
    "\n",
    "t = df[\"date\"]\n",
    "\n",
    "# Plot Actual vs Predicted Values with Annotations for Train and Test\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Actual Values\n",
    "plt.plot(\n",
    "    t,\n",
    "    y,\n",
    "    label=\"Actual Values\",\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    t,\n",
    "    y_pred,\n",
    "    label=\"Predicted Values\",\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.axvspan(\n",
    "    t.iloc[train_idxs_0[0]],\n",
    "    t.iloc[train_idxs_0[-1]],\n",
    "    color=\"lightgreen\",\n",
    "    alpha=0.3,\n",
    "    label=\"Training Period\",\n",
    ")\n",
    "\n",
    "plt.axvspan(\n",
    "    t.iloc[train_idxs_1[0]],\n",
    "    t.iloc[train_idxs_1[-1]],\n",
    "    color=\"lightgreen\",\n",
    "    alpha=0.3,\n",
    "    # label=\"Training Period\",\n",
    ")\n",
    "\n",
    "# Annotate Test Period\n",
    "plt.axvspan(\n",
    "    t.iloc[test_idxs[0]],\n",
    "    t.iloc[test_idxs[-1]],\n",
    "    color=\"lightcoral\",\n",
    "    alpha=0.3,\n",
    "    label=\"Test Period\",\n",
    ")\n",
    "\n",
    "plt.title(\"Actual vs Predicted Values (with Train/Test Annotation)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"predictions_vs_actual.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff97a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "importance = model.get_booster().get_score(importance_type=\"weight\")\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 30 most important features\n",
    "top_features = sorted_importance[:30]\n",
    "\n",
    "# Print the most important features\n",
    "print(\"Top 30 Most Important Features:\")\n",
    "for feature, score in top_features:\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "xgb.plot_importance(model, max_num_features=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80afe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopExecution(Exception):\n",
    "    pass\n",
    "\n",
    "raise StopExecution(\"Logical end of this notebook. Remaining cells are deprecated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b9f38",
   "metadata": {},
   "source": [
    "## (Currently) Deprecated Code Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3342c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Implementation of Blocking Time Series\n",
    "\n",
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.8 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]\n",
    "\n",
    "# btscv = BlockingTimeSeriesSplit(n_splits=TS_NSPLITS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the time series split\n",
    "TS_NSPLITS = 20\n",
    "tscv = TimeSeriesSplit(n_splits=TS_NSPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134884de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend-Seasoning-Noise Decomposition\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(\n",
    "    y, model=\"additive\", period=12\n",
    ")  # Example: monthly seasonality\n",
    "y_train_trend = result.trend\n",
    "y_train_seasonal = result.seasonal\n",
    "y_train_residual = result.resid\n",
    "\n",
    "y_train_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier Decompositon\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.fft import fftfreq\n",
    "from scipy.fft import ifft\n",
    "\n",
    "time_series = y_test.values \n",
    "n_samples = len(time_series)\n",
    "delta_t = 1\n",
    "\n",
    "fft_values = fft(time_series)      # Compute Fourier coefficients\n",
    "frequencies = fftfreq(n_samples, d=delta_t)  # Get corresponding frequencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.stem(frequencies[:n_samples // 2], np.abs(fft_values[:n_samples // 2]))\n",
    "plt.title(\"Frequency Spectrum\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "\n",
    "# Filter: Remove low frequencies (trend) and/or specific seasonal frequencies\n",
    "filter_mask = (np.abs(frequencies) > 0.01) & (np.abs(frequencies) != 1/365)\n",
    "filtered_fft_values = fft_values * filter_mask \n",
    "\n",
    "# Reconstruct the time series (detrended and deseasonalized)\n",
    "reconstructed_signal = ifft(filtered_fft_values).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca45a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists for the evaluation scores\n",
    "rmses = []\n",
    "maes = []\n",
    "models = []\n",
    "\n",
    "for fold, (train_idxs, test_idx) in enumerate(tscv.split(X)):\n",
    "    X_train, X_test = X.iloc[train_idxs], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idxs], y.iloc[test_idx]\n",
    "\n",
    "    xgb_regressor = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        eval_metric=\"rmse\",\n",
    "    )\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_regressor,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    model = grid_search.best_estimator_\n",
    "    models.append(model)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    rmses.append(rmse)\n",
    "    maes.append(mae)\n",
    "\n",
    "rmses = np.array(rmses)\n",
    "maes = np.array(maes)\n",
    "\n",
    "best_model_index = np.argmin(rmses)\n",
    "best_model = models[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d88197",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Model is from Fold {best_model_index + 1}\")\n",
    "print(f\"Best RMSE: {rmses[best_model_index]:.2f}\")\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Average RMSE: {np.mean(rmses):.2f}\")\n",
    "print(f\"Average MAE: {np.mean(maes):.2f}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
