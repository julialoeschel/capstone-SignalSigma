{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation \n",
    "\n",
    "In this notebook, we inspect the data frames from different sources and prepare them for a unifying merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from signal_sigma.config.cfg_legacy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin of META era\n",
    "START_DATE = \"2012-12-30\"\n",
    "\n",
    "NB_NUMBER = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks from `yfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_0 = {}\n",
    "\n",
    "for ticker in STOCK_TICKERS:\n",
    "    csvname = ticker.lower() + \".csv\"\n",
    "    csvpath_rel = os.path.join(DATA_STOCKS_DIR_RELPATH, csvname)\n",
    "    dfs_0[ticker] = load_df_from_csv(csvpath_rel, NB_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_0[\"AMZN\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Data Frame Processing\n",
    "\n",
    "- Remove the null / header\n",
    "- Make some features Engineering\n",
    "- Change the column name\n",
    "- Change the time type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "for ticker in STOCK_TICKERS:\n",
    "    df = dfs_0[ticker]\n",
    "\n",
    "    # Remove rows containing any missing values.\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Calculate new features based on price data\n",
    "\n",
    "    # Calculate the difference between the high and low price for each day.\n",
    "    df[\"delta_price\"] = df[\"high\"] - df[\"low\"]\n",
    "    # Calculate the average of the close, high, low, and open prices\n",
    "    # as a metric for the day's price distribution.\n",
    "    # WARNING: This might not be a standard financial metric. In consequence, \n",
    "    # this is also true for the following derived metrics.\n",
    "    df[\"avg_price\"] = (df[\"close\"] + df[\"high\"] + df[\"low\"] + df[\"open\"]) / 4\n",
    "    # Calculate the ratio of the delta price to the average price.\n",
    "    df[\"price_ratio\"] = df[\"delta_price\"] / df[\"avg_price\"]\n",
    "    # Calculate the difference between the trading volume and the average price\n",
    "    df[\"invest\"] = df[\"volume\"] * df[\"avg_price\"]\n",
    "\n",
    "    # Other alternatives\n",
    "    # XXX: Uncomment when time is ripe.\n",
    "\n",
    "    # # Median Price (avoids extreme fluctuations)\n",
    "    # df[\"median_price\"] = (df[\"high\"] + df[\"low\"]) / 2\n",
    "\n",
    "    # # Adjusted OHLC Mean (weights closing price higher)\n",
    "    # df[\"adj_avg_price\"] = (df[\"close\"] * 2 + df[\"high\"] + df[\"low\"] + df[\"open\"]) / 5\n",
    "\n",
    "    # # Typical Price (common in financial indicators)\n",
    "    # df[\"typical_price\"] = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "\n",
    "    # # Weighted Price (emphasizes high price more)\n",
    "    # df[\"weighted_price\"] = (df[\"high\"] * 0.5 + df[\"low\"] * 0.25 + df[\"close\"] * 0.25)\n",
    "\n",
    "    # # Volume-Weighted Average Price (VWAP)\n",
    "    # df[\"vwap\"] = (df[\"close\"] * df[\"volume\"]).cumsum() / df[\"volume\"].cumsum()\n",
    "\n",
    "    # # Exponential Moving Average (EMA-based mean for responsiveness)\n",
    "    # df[\"ema_avg_price\"] = df[\"close\"].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "    # Include ticker in column names (with exception of date)\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            col: f\"{col}_{ticker}\" for col in df.columns if col != \"date\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    dfs[ticker] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find the Max and Min of the Data column in each companies stock Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_summary = {}\n",
    "\n",
    "for ticker in STOCK_TICKERS:\n",
    "    df = dfs[ticker]\n",
    "    dr = {}\n",
    "    dr[\"min_date\"] = df[\"date\"].min()\n",
    "    dr[\"max_date\"] = df[\"date\"].max()\n",
    "    dr[\"duration\"] = dr[\"max_date\"] - dr[\"min_date\"]\n",
    "    dct_summary[ticker] = dr\n",
    "\n",
    "# Create a Pandas DataFrame to display the results\n",
    "df_summary = pd.DataFrame.from_dict(dct_summary, orient=\"index\")\n",
    "df_summary.index.name = \"Stock\"\n",
    "\n",
    "print(\"\\nSummary: Stock Ranges\\n\")\n",
    "print(df_summary.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above result , It seems that the META is started from 2012 while almost the others started from 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the cleaned dfs to disk\n",
    "for ticker in STOCK_TICKERS:\n",
    "    df = dfs[ticker]\n",
    "    csvpath_rel = os.path.join(DATA_STOCKS_DIR_RELPATH, ticker.lower() + \".csv\")\n",
    "    store_df_as_csv(df, csvpath_rel, NB_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Indices/Indexoids from `yfinance`\n",
    "\n",
    "- Indices\n",
    "- Commodities\n",
    "- Sector ETFs (Proxies)\n",
    "- Other Market Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath_rel = DATA_YF_MIF_RELPATH\n",
    "df_idxs_0 = load_df_from_csv(csvpath_rel, NB_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idxs_0.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame has some missing values that need to be checked.\n",
    "\n",
    "Let us restrict our analysis to the META era (after the 2012-05-31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idxs_1 = df_idxs_0[df_idxs_0[\"date\"] > START_DATE]\n",
    "df_idxs_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of missing values for the market indices\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "msno.matrix(df_idxs_1)\n",
    "plt.title(f\"Missing Value Matrix -- Macros\")\n",
    "\n",
    "plt.savefig(os.path.join(PLOTS_PATH, \"missing-value-matrix.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idxs_2 = df_idxs_1.dropna()\n",
    "df_idxs_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the cleaned df to disk.\n",
    "csvpath_rel = DATA_YF_MIF_RELPATH\n",
    "store_df_as_csv(df_idxs_2, csvpath_rel, NB_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Indicators from `fred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath_rel = DATA_FED_CEI_RELPATH\n",
    "df_inds_0 = load_df_from_csv(csvpath_rel, NB_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inds_0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inds_1 = df_inds_0[df_inds_0[\"date\"] > START_DATE]\n",
    "df_inds_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of missing values for the market indicators\n",
    "\n",
    "msno.matrix(df_inds_1)\n",
    "plt.title(f\"Missing Value Matrix - FED\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_inds_1.columns if col not in [\"gdp\"]]\n",
    "\n",
    "df_inds_2 = df_inds_1[cols].dropna()\n",
    "df_inds_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the cleaned df to disk.\n",
    "csvpath_rel = DATA_FED_CEI_RELPATH\n",
    "store_df_as_csv(df_inds_2, csvpath_rel, NB_NUMBER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
