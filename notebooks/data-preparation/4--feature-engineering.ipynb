{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this notebook, we amend the main data frame by some features that may be relevant for inferring conclusions and predictions from the data.\n",
    "\n",
    "The time series composition will be added in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "from signal_sigma.config.cfg_legacy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_NUMBER = 4\n",
    "\n",
    "relpath = \"main.csv\"\n",
    "\n",
    "# Original data frame\n",
    "df = load_df_from_csv(relpath, NB_NUMBER)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Related Features -- 1\n",
    "\n",
    "# 0 = Monday, ..., 6 = Sunday\n",
    "df[\"weekday\"] = df[\"date\"].dt.dayofweek\n",
    "\n",
    "# Calendar week (1-53)\n",
    "df[\"calendar_week\"] = df[\"date\"].dt.isocalendar().week\n",
    "\n",
    "# 1 = January, ..., 12 = December\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "\n",
    "# Quarter (1-4)\n",
    "df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "\n",
    "# Year\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "\n",
    "# Last day of month, quarter, year\n",
    "df[\"is_month_end\"] = df[\"date\"].dt.is_month_end.astype(int)\n",
    "df[\"is_quarter_end\"] = df[\"date\"].dt.is_quarter_end.astype(int)\n",
    "df[\"is_year_end\"] = df[\"date\"].dt.is_year_end.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Related Features -- 2\n",
    "\n",
    "# # WARNING: Not tested yet!\n",
    "\n",
    "# # NOTE: Actually, at an earlier stage, holidays were already filtered\n",
    "# # (due to filtering a subframe and inner joining the frames). But perhaps,\n",
    "# # it better fits here.\n",
    "\n",
    "# # US holidays indicator\n",
    "# us_holidays = holidays.US()\n",
    "# df[\"is_holiday\"] = df[\"date\"].apply(lambda dt: dt in us_holidays)\n",
    "\n",
    "# # Trading day indicator\n",
    "# df[\"is_trading_day\"] = (~df[\"is_holiday\"]) & (~df[\"weekday\"].isin([5, 6]))\n",
    "\n",
    "# # Last trading day of month, quarter, year\n",
    "# # NOTE: It is decisive that the rows are already\n",
    "# # ordered by ascending date!\n",
    "\n",
    "# PERIODS = {\n",
    "#     \"M\": \"month\",\n",
    "#     \"Q\": \"quarter\",\n",
    "#     \"Y\": \"year\",\n",
    "# }\n",
    "\n",
    "# is_trading_day = df[\"is_trading_day\"] == True\n",
    "# # Dates that are trading days\n",
    "# left = df.loc[is_trading_day, \"date\"]\n",
    "\n",
    "# for code, period in PERIODS.items():\n",
    "#     # Corresponding maximum of (trading day) date when grouped\n",
    "#     # by period.\n",
    "#     right = df.loc[is_trading_day].groupby(\n",
    "#         df.loc[is_trading_day, \"date\"].dt.to_period(code)\n",
    "#     )[\"date\"].transform(\"max\")\n",
    "#     # Whether date coincide with maximum day in its period group.\n",
    "#     df.loc[is_trading_day, f\"is_trading_{period}_end\"] = (left == right).astype(int)\n",
    "#     # Assign false to non-trading days dates (not yet adressed).\n",
    "#     df[f\"is_trading_{period}_end\"] = df[f\"is_trading_{period}_end\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment -- Total and per Stock ratios\n",
    "\n",
    "cols_0 = cartprod(\"invest\", STOCK_TICKERS)\n",
    "\n",
    "# Total Investment\n",
    "df[\"invest_total\"] = df[cols_0].sum(axis=1)\n",
    "\n",
    "# Per Stock Ratio Investment\n",
    "cols = cartprod(\"invest\", STOCK_TICKERS, \"ratio\")\n",
    "df[cols] = df[cols_0].div(df[\"invest_total\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment -- Differencing and Lagging\n",
    "\n",
    "cols_0 = cartprod(\"invest\", STOCK_TICKERS, \"ratio\")\n",
    "cols = cartprod(cols_0, \"diff\")\n",
    "df[cols] = df[cols_0].diff()\n",
    "\n",
    "df[\"invest_total_lag_1\"] = df[\"invest_total\"].shift(1)\n",
    "df[\"invest_total_diff\"] = df[\"invest_total\"].diff()\n",
    "df[\"invest_total_rolling_mean_5\"] = df[\"invest_total\"].rolling(window=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary (Backward) Differencing for Some Macroeconomical Indicators\n",
    "\n",
    "cols_0 = [\n",
    "    \"cpi\",\n",
    "    \"fed_rate\",\n",
    "    \"consumer_confidence\",\n",
    "    \"vix_index\",\n",
    "    \"oil\",\n",
    "    \"nonfarm_payrolls\",\n",
    "    \"treasury_yield\",\n",
    "    \"industrial_production\",\n",
    "    \"retail_sales\",\n",
    "    \"pmi\",\n",
    "    \"s&p500_index\",\n",
    "    \"dow_jones_index\",\n",
    "    \"nasdaq_composite\",\n",
    "    \"russell2000_index\",\n",
    "    \"dollar_index_dxy\",\n",
    "    \"gold_futures\",\n",
    "    \"wti_oil_futures\",\n",
    "    \"copper_futures\",\n",
    "    \"brent_crude_futures\",\n",
    "    \"tech_sector_etf\",\n",
    "    \"energy_sector_etf\",\n",
    "    \"financial_sector_etf\",\n",
    "    \"consumerdiscretionary_etf\",\n",
    "    \"lithium_etf\",\n",
    "    \"semiconductor_etf\",\n",
    "    \"electricity_proxy\",\n",
    "]\n",
    "\n",
    "cols = cartprod(cols_0, \"diff\")\n",
    "df[cols] = df[cols_0].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "STOCK_LAGS = [1, 3, 5, 10]\n",
    "\n",
    "STOCK_COLS = [\"close\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "ROLLING_WINDOWS = [5, 20]\n",
    "\n",
    "cols_0 = cartprod(STOCK_COLS, STOCK_TICKERS)\n",
    "\n",
    "# Primary (Backward) Difference\n",
    "cols = cartprod(cols_0, \"diff\")\n",
    "df[cols] = df[cols_0].diff()\n",
    "\n",
    "# Rolling Mean and Std\n",
    "for window in ROLLING_WINDOWS:\n",
    "    cols = cartprod(cols_0, f\"rolling_mean_{window}\")\n",
    "    df[cols] = df[cols_0].rolling(window=window).mean()\n",
    "\n",
    "    cols = cartprod(cols_0, f\"rolling_std_{window}\")\n",
    "    df[cols] = df[cols_0].rolling(window=window).std()\n",
    "\n",
    "# Lagged Features\n",
    "for lag in STOCK_LAGS:\n",
    "    cols = cartprod(cols_0, f\"lag_{lag}\")\n",
    "    df[cols] = df[cols_0].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Specific Columns\n",
    "\n",
    "STOCK_LAGS = [1, 3, 5, 10]\n",
    "\n",
    "STOCK_COLS = [\"close\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "ROLLING_WINDOWS = [5, 20]\n",
    "\n",
    "cols_0 = cartprod(STOCK_COLS, STOCK_TICKERS)\n",
    "\n",
    "# Primary (Backward) Difference\n",
    "cols = cartprod(cols_0, \"diff\")\n",
    "df[cols] = df[cols_0].diff()\n",
    "\n",
    "# Rolling Mean and Std\n",
    "for window in ROLLING_WINDOWS:\n",
    "    cols = cartprod(cols_0, f\"rolling_mean_{window}\")\n",
    "    df[cols] = df[cols_0].rolling(window=window).mean()\n",
    "\n",
    "    cols = cartprod(cols_0, f\"rolling_std_{window}\")\n",
    "    df[cols] = df[cols_0].rolling(window=window).std()\n",
    "\n",
    "# Lagged Features\n",
    "for lag in STOCK_LAGS:\n",
    "    cols = cartprod(cols_0, f\"lag_{lag}\")\n",
    "    df[cols] = df[cols_0].shift(lag)\n",
    "\n",
    "# RSI -- Relative Strength Index\n",
    "# RSI measures the momentum of price movements, helping to determine\n",
    "# whether an asset is overbought or oversold.\n",
    "for ticker in STOCK_TICKERS:\n",
    "    ser = df[f\"close_{ticker}\"]\n",
    "    df[f\"{ticker}_rsi\"] = ta.rsi(ser, length=14)\n",
    "\n",
    "# MACD -- Moving Average Convergence Divergence\n",
    "# MACDs compare two moving averages to analyze price momentum.\n",
    "for ticker in STOCK_TICKERS:\n",
    "    ser = df[f\"close_{ticker}\"]\n",
    "    macd = ta.macd(ser)\n",
    "    df[f\"{ticker}_MACD\"] = macd[\"MACD_12_26_9\"]\n",
    "    df[f\"{ticker}_MACD_signal\"] = macd[\"MACDs_12_26_9\"]\n",
    "    df[f\"{ticker}_MACD_hist\"] = macd[\"MACDh_12_26_9\"]\n",
    "\n",
    "# Volume-based Features\n",
    "\n",
    "cols_0 = cartprod(\"volume\", STOCK_TICKERS)\n",
    "cols = cartprod(cols_0, \"log\")\n",
    "df[cols] = np.log1p(df[cols_0])\n",
    "\n",
    "cols_0 = cartprod(\"volume\", STOCK_TICKERS, \"log\")\n",
    "cols = cartprod(cols_0, \"diff\")\n",
    "df[cols] = df[cols_0].diff()\n",
    "\n",
    "# Further Primary (Backward) Differences\n",
    "\n",
    "cols_further = [\n",
    "    \"delta_price\",\n",
    "    \"avg_price\",\n",
    "    \"price_ratio\",\n",
    "    \"invest\",\n",
    "]\n",
    "\n",
    "cols_0 = cartprod(cols_further, STOCK_TICKERS)\n",
    "cols = cartprod(cols_0, \"diff\")\n",
    "df[cols] = df[cols_0].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Cleaning Step\n",
    "# Drop rows with NaN values caused by differencing, rolling, and shifting\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store final DataFrame on disk\n",
    "\n",
    "relpath = \"main.csv\"\n",
    "store_df_as_csv(df, relpath, NB_NUMBER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
