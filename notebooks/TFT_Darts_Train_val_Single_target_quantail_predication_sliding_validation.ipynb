{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[f'volume_{target_stock}','Bitcoin']]\n",
    "df_col = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 24.0 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 22.0 K\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K\n",
      "10 | lstm_encoder                      | LSTM                             | 66.6 K\n",
      "11 | lstm_decoder                      | LSTM                             | 66.6 K\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K \n",
      "18 | output_layer                      | Linear                           | 195   \n",
      "----------------------------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "2.557     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading data...\n",
      "[DEBUG] df shape: (2847, 181), index: 2014-01-02 00:00:00 to 2025-04-28 00:00:00\n",
      "[DEBUG] df NaN: 0\n",
      "[DEBUG] features shape : (2847, 12), type: <class 'pandas.core.frame.DataFrame'> \n",
      "[DEBUG] features index: 2014-01-02 00:00:00 to 2025-04-28 00:00:00\n",
      "[DEBUG] features NaN: 0\n",
      "[DEBUG] full_df shape: (4135, 13), index: 2014-01-02 00:00:00 to 2025-04-28 00:00:00\n",
      "[DEBUG] full_df NaN after interpolate: 0\n",
      "[DEBUG] raw_target len: 4135, freq: D, NaNs: 0\n",
      "[DEBUG] raw_target shape : (4135, 1, 1), type: <class 'darts.timeseries.TimeSeries'> \n",
      "[DEBUG] raw_target index-len: 2014-01-02 00:00:00 to 2025-04-28 00:00:00\n",
      "[DEBUG] raw_covariates shape : (4135, 12, 1), type: <class 'darts.timeseries.TimeSeries'> \n",
      "[DEBUG] raw_covariates index-len: 2014-01-02 00:00:00 to 2025-04-28 00:00:00\n",
      "[INFO] input_len=90, output_len=15, window_step=30, total_len=4135\n",
      "\n",
      "[INFO] Window 1/5\n",
      "[DEBUG] train_end=3970, val_start=3880, val_end=3985\n",
      "[DEBUG] train_target: 2014-01-02 00:00:00 to 2024-11-14 00:00:00, len=3970\n",
      "[DEBUG] val_target: 2024-08-17 00:00:00 to 2024-11-29 00:00:00, len=105\n",
      "[DEBUG] val_covariates: 2024-08-17 00:00:00 to 2024-12-14 00:00:00, len=120\n",
      "[DEBUG] Scaled train_target shape: (3970, 1, 1), val_target shape: (105, 1, 1)\n",
      "[DEBUG] Scaled train_covariates shape: (3970, 12, 1), val_covariates shape: (120, 12, 1)\n",
      "Epoch 4: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s, loss=0.0253, train_loss=0.0277, val_loss=0.038] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s, loss=0.0253, train_loss=0.0277, val_loss=0.038]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 24.0 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 22.0 K\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K\n",
      "10 | lstm_encoder                      | LSTM                             | 66.6 K\n",
      "11 | lstm_decoder                      | LSTM                             | 66.6 K\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K \n",
      "18 | output_layer                      | Linear                           | 195   \n",
      "----------------------------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "2.557     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] forecast_p50: 2024-11-30 00:00:00 to 2024-12-14 00:00:00, len=15\n",
      "[DEBUG] actual: N/A to N/A, len=0\n",
      "[WARNING] Skipping metrics for window 1: No overlapping timestamps.\n",
      "\n",
      "[INFO] Window 2/5\n",
      "[DEBUG] train_end=4000, val_start=3910, val_end=4015\n",
      "[DEBUG] train_target: 2014-01-02 00:00:00 to 2024-12-14 00:00:00, len=4000\n",
      "[DEBUG] val_target: 2024-09-16 00:00:00 to 2024-12-29 00:00:00, len=105\n",
      "[DEBUG] val_covariates: 2024-09-16 00:00:00 to 2025-01-13 00:00:00, len=120\n",
      "[DEBUG] Scaled train_target shape: (4000, 1, 1), val_target shape: (105, 1, 1)\n",
      "[DEBUG] Scaled train_covariates shape: (4000, 12, 1), val_covariates shape: (120, 12, 1)\n",
      "Epoch 4: 100%|██████████| 62/62 [00:19<00:00,  3.18it/s, loss=0.0257, train_loss=0.0236, val_loss=0.160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 62/62 [00:19<00:00,  3.18it/s, loss=0.0257, train_loss=0.0236, val_loss=0.160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 24.0 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 22.0 K\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K\n",
      "10 | lstm_encoder                      | LSTM                             | 66.6 K\n",
      "11 | lstm_decoder                      | LSTM                             | 66.6 K\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K \n",
      "18 | output_layer                      | Linear                           | 195   \n",
      "----------------------------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "2.557     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] forecast_p50: 2024-12-30 00:00:00 to 2025-01-13 00:00:00, len=15\n",
      "[DEBUG] actual: N/A to N/A, len=0\n",
      "[WARNING] Skipping metrics for window 2: No overlapping timestamps.\n",
      "\n",
      "[INFO] Window 3/5\n",
      "[DEBUG] train_end=4030, val_start=3940, val_end=4045\n",
      "[DEBUG] train_target: 2014-01-02 00:00:00 to 2025-01-13 00:00:00, len=4030\n",
      "[DEBUG] val_target: 2024-10-16 00:00:00 to 2025-01-28 00:00:00, len=105\n",
      "[DEBUG] val_covariates: 2024-10-16 00:00:00 to 2025-02-12 00:00:00, len=120\n",
      "[DEBUG] Scaled train_target shape: (4030, 1, 1), val_target shape: (105, 1, 1)\n",
      "[DEBUG] Scaled train_covariates shape: (4030, 12, 1), val_covariates shape: (120, 12, 1)\n",
      "Epoch 4: 100%|██████████| 63/63 [00:20<00:00,  3.13it/s, loss=0.0253, train_loss=0.0199, val_loss=0.0339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 63/63 [00:20<00:00,  3.13it/s, loss=0.0253, train_loss=0.0199, val_loss=0.0339]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 24.0 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 22.0 K\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K\n",
      "10 | lstm_encoder                      | LSTM                             | 66.6 K\n",
      "11 | lstm_decoder                      | LSTM                             | 66.6 K\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K \n",
      "18 | output_layer                      | Linear                           | 195   \n",
      "----------------------------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "2.557     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] forecast_p50: 2025-01-29 00:00:00 to 2025-02-12 00:00:00, len=15\n",
      "[DEBUG] actual: N/A to N/A, len=0\n",
      "[WARNING] Skipping metrics for window 3: No overlapping timestamps.\n",
      "\n",
      "[INFO] Window 4/5\n",
      "[DEBUG] train_end=4060, val_start=3970, val_end=4075\n",
      "[DEBUG] train_target: 2014-01-02 00:00:00 to 2025-02-12 00:00:00, len=4060\n",
      "[DEBUG] val_target: 2024-11-15 00:00:00 to 2025-02-27 00:00:00, len=105\n",
      "[DEBUG] val_covariates: 2024-11-15 00:00:00 to 2025-03-14 00:00:00, len=120\n",
      "[DEBUG] Scaled train_target shape: (4060, 1, 1), val_target shape: (105, 1, 1)\n",
      "[DEBUG] Scaled train_covariates shape: (4060, 12, 1), val_covariates shape: (120, 12, 1)\n",
      "Epoch 4: 100%|██████████| 63/63 [00:21<00:00,  2.87it/s, loss=0.0246, train_loss=0.0235, val_loss=0.0546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 63/63 [00:21<00:00,  2.87it/s, loss=0.0246, train_loss=0.0235, val_loss=0.0546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 24.0 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 22.0 K\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K\n",
      "10 | lstm_encoder                      | LSTM                             | 66.6 K\n",
      "11 | lstm_decoder                      | LSTM                             | 66.6 K\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K \n",
      "18 | output_layer                      | Linear                           | 195   \n",
      "----------------------------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "2.557     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] forecast_p50: 2025-02-28 00:00:00 to 2025-03-14 00:00:00, len=15\n",
      "[DEBUG] actual: N/A to N/A, len=0\n",
      "[WARNING] Skipping metrics for window 4: No overlapping timestamps.\n",
      "\n",
      "[INFO] Window 5/5\n",
      "[DEBUG] train_end=4090, val_start=4000, val_end=4105\n",
      "[DEBUG] train_target: 2014-01-02 00:00:00 to 2025-03-14 00:00:00, len=4090\n",
      "[DEBUG] val_target: 2024-12-15 00:00:00 to 2025-03-29 00:00:00, len=105\n",
      "[DEBUG] val_covariates: 2024-12-15 00:00:00 to 2025-04-13 00:00:00, len=120\n",
      "[DEBUG] Scaled train_target shape: (4090, 1, 1), val_target shape: (105, 1, 1)\n",
      "[DEBUG] Scaled train_covariates shape: (4090, 12, 1), val_covariates shape: (120, 12, 1)\n",
      "Epoch 2:  27%|██▋       | 17/62 [17:03<45:08, 60.18s/it, loss=0.049, train_loss=0.0482, val_loss=0.0636]]\n",
      "Epoch 1:  58%|█████▊    | 36/62 [16:30<11:55, 27.50s/it, loss=0.0489, train_loss=0.0425, val_loss=0.0596]\n",
      "Epoch 4: 100%|██████████| 64/64 [00:21<00:00,  3.02it/s, loss=0.0294, train_loss=0.0257, val_loss=0.0457]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 64/64 [00:21<00:00,  3.02it/s, loss=0.0294, train_loss=0.0257, val_loss=0.0457]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "[DEBUG] forecast_p50: 2025-03-30 00:00:00 to 2025-04-13 00:00:00, len=15\n",
      "[DEBUG] actual: N/A to N/A, len=0\n",
      "[WARNING] Skipping metrics for window 5: No overlapping timestamps.\n",
      "\n",
      "[INFO] Aggregated Performance:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 179\u001b[39m\n\u001b[32m    177\u001b[39m metrics_df = pd.DataFrame(all_metrics)\n\u001b[32m    178\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[INFO] Aggregated Performance:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmetrics_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# === Step 15: Save Metrics === #\u001b[39;00m\n\u001b[32m    182\u001b[39m metrics_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33maggregated_window_metrics.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/capstone-SignalSigma/.venv/lib/python3.11/site-packages/pandas/core/generic.py:11537\u001b[39m, in \u001b[36mNDFrame.describe\u001b[39m\u001b[34m(self, percentiles, include, exclude)\u001b[39m\n\u001b[32m  11295\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m  11296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdescribe\u001b[39m(\n\u001b[32m  11297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11300\u001b[39m     exclude=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  11301\u001b[39m ) -> Self:\n\u001b[32m  11302\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  11303\u001b[39m \u001b[33;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[32m  11304\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  11535\u001b[39m \u001b[33;03m    max            NaN      3.0\u001b[39;00m\n\u001b[32m  11536\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11537\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdescribe_ndframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  11538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  11539\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  11540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  11541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  11542\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mdescribe\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/capstone-SignalSigma/.venv/lib/python3.11/site-packages/pandas/core/methods/describe.py:91\u001b[39m, in \u001b[36mdescribe_ndframe\u001b[39m\u001b[34m(obj, include, exclude, percentiles)\u001b[39m\n\u001b[32m     87\u001b[39m     describer = SeriesDescriber(\n\u001b[32m     88\u001b[39m         obj=cast(\u001b[33m\"\u001b[39m\u001b[33mSeries\u001b[39m\u001b[33m\"\u001b[39m, obj),\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     describer = \u001b[43mDataFrameDescriber\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDataFrame\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m result = describer.describe(percentiles=percentiles)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/capstone-SignalSigma/.venv/lib/python3.11/site-packages/pandas/core/methods/describe.py:160\u001b[39m, in \u001b[36mDataFrameDescriber.__init__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28mself\u001b[39m.exclude = exclude\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m obj.columns.size == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot describe a DataFrame without columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(obj)\n",
      "\u001b[31mValueError\u001b[39m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import copy\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mae, rmse, smape, mape, r2_score, mse, rmsle\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Step 1: Load and Prepare Data === #\n",
    "print(\"\\n[INFO] Loading data...\")\n",
    "df = pd.read_csv(\"../data/Stock_market_data/clean_stock_data_with_time_index.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "df = df.sort_index()\n",
    "raw_main_df = copy.deepcopy(df)\n",
    "print(f\"[DEBUG] df shape: {df.shape}, index: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"[DEBUG] df NaN: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# === Step 2: Select Target Stock === #\n",
    "target_stock = \"AAPL\"\n",
    "drop_cols = [f\"open_{target_stock}\", f\"low_{target_stock}\", f\"high_{target_stock}\"]\n",
    "df.drop(columns=drop_cols, inplace=True)\n",
    "target_df = df[[f\"close_{target_stock}\"]].rename(columns={f\"close_{target_stock}\": \"target\"})\n",
    "df.drop(columns=f\"close_{target_stock}\", inplace=True)\n",
    "df = df[[f'volume_{target_stock}','Bitcoin']]\n",
    "df_col = df.columns.tolist()\n",
    "\n",
    "# === Step 3: Time Feature Engineering === #\n",
    "features = pd.DataFrame(index=target_df.index)\n",
    "features[\"month\"] = features.index.month\n",
    "features[\"day_of_week\"] = features.index.dayofweek\n",
    "features[\"day_of_month\"] = features.index.day\n",
    "features[\"week\"] = features.index.isocalendar().week.values.astype(int)\n",
    "features[\"quarter\"] = features.index.quarter\n",
    "\n",
    "def encode_cyclical(df, col, max_val):\n",
    "    df[f\"{col}_sin\"] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[f\"{col}_cos\"] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    df.drop(columns=[col], inplace=True)\n",
    "\n",
    "for col, max_v in zip([\"month\", \"day_of_week\", \"day_of_month\", \"week\", \"quarter\"], [12, 7, 31, 53, 4]):\n",
    "    encode_cyclical(features, col, max_v)\n",
    "\n",
    "features = pd.concat([features, df[df_col]], axis=1)\n",
    "print(f\"[DEBUG] features shape : {features.shape}, type: {type(features)} \")\n",
    "print(f\"[DEBUG] features index: {features.index.min()} to {features.index.max()}\")\n",
    "print(f\"[DEBUG] features NaN: {features.isnull().sum().sum()}\")\n",
    "\n",
    "# === Step 4: Interpolate Missing Values === #\n",
    "full_df = pd.concat([target_df, features], axis=1).resample(\"D\").interpolate(method=\"linear\")\n",
    "print(f\"[DEBUG] full_df shape: {full_df.shape}, index: {full_df.index.min()} to {full_df.index.max()}\")\n",
    "print(f\"[DEBUG] full_df NaN after interpolate: {full_df.isnull().sum().sum()}\")\n",
    "\n",
    "# === Step 5: Convert to TimeSeries === #\n",
    "raw_target = TimeSeries.from_dataframe(full_df, value_cols=\"target\", freq=\"D\")\n",
    "raw_covariates = TimeSeries.from_dataframe(full_df, value_cols=features.columns.tolist())\n",
    "print(f\"[DEBUG] raw_target len: {len(raw_target)}, freq: {raw_target.freq_str}, NaNs: {np.isnan(raw_target.values()).sum()}\")\n",
    "print(f\"[DEBUG] raw_target shape : {raw_target.shape}, type: {type(raw_target)} \")\n",
    "print(f\"[DEBUG] raw_target index-len: {raw_target.time_index.min()} to {raw_target.time_index.max()}\")\n",
    "print(f\"[DEBUG] raw_covariates shape : {raw_covariates.shape}, type: {type(raw_covariates)} \")\n",
    "print(f\"[DEBUG] raw_covariates index-len: {raw_covariates.time_index.min()} to {raw_covariates.time_index.max()}\")\n",
    "\n",
    "# === Step 6: Define Parameters for Sliding Window === #\n",
    "output_len = 15\n",
    "input_len = output_len * 6\n",
    "num_windows = 5\n",
    "window_step = 30\n",
    "\n",
    "if input_len <= output_len:\n",
    "    raise ValueError(\"[ERROR] input_len must be greater than output_len to create a valid window.\")\n",
    "\n",
    "print(f\"[INFO] input_len={input_len}, output_len={output_len}, window_step={window_step}, total_len={len(raw_target)}\")\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# === Step 7: Loop Over Sliding Windows === #\n",
    "for i in range(num_windows):\n",
    "    print(f\"\\n[INFO] Window {i+1}/{num_windows}\")\n",
    "\n",
    "    train_end = len(raw_target) - (num_windows - i) * window_step - output_len\n",
    "    val_start = train_end - input_len\n",
    "    val_end = train_end + output_len\n",
    "\n",
    "    print(f\"[DEBUG] train_end={train_end}, val_start={val_start}, val_end={val_end}\")\n",
    "\n",
    "    if val_start < 0 or val_end + output_len > len(raw_target):\n",
    "        print(f\"[WARNING] Skipping window {i+1} due to index bounds.\")\n",
    "        continue\n",
    "\n",
    "    train_target = raw_target[:train_end]\n",
    "    val_target = raw_target[val_start:val_end]\n",
    "    train_covariates = raw_covariates[:train_end]\n",
    "    val_covariates = raw_covariates[val_start:val_end + output_len]\n",
    "\n",
    "    print(f\"[DEBUG] train_target: {train_target.start_time()} to {train_target.end_time()}, len={len(train_target)}\")\n",
    "    print(f\"[DEBUG] val_target: {val_target.start_time()} to {val_target.end_time()}, len={len(val_target)}\")\n",
    "    print(f\"[DEBUG] val_covariates: {val_covariates.start_time()} to {val_covariates.end_time()}, len={len(val_covariates)}\")\n",
    "\n",
    "    # === Step 8: Scaling per Window === #\n",
    "    t_scaler = Scaler()\n",
    "    f_scaler = Scaler()\n",
    "    train_target_scaled = t_scaler.fit_transform(train_target)\n",
    "    val_target_scaled = t_scaler.transform(val_target)\n",
    "    train_cov_scaled = f_scaler.fit_transform(train_covariates)\n",
    "    val_cov_scaled = f_scaler.transform(val_covariates)\n",
    "\n",
    "    print(f\"[DEBUG] Scaled train_target shape: {train_target_scaled.shape}, val_target shape: {val_target_scaled.shape}\")\n",
    "    print(f\"[DEBUG] Scaled train_covariates shape: {train_cov_scaled.shape}, val_covariates shape: {val_cov_scaled.shape}\")\n",
    "\n",
    "    # === Step 9: Model Definition === #\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=input_len,\n",
    "        output_chunk_length=output_len,\n",
    "        hidden_size=64,\n",
    "        lstm_layers=2,\n",
    "        dropout=0.3,\n",
    "        batch_size=64,\n",
    "        n_epochs=5,\n",
    "        num_attention_heads=4,\n",
    "        likelihood=QuantileRegression([0.1, 0.5, 0.9]),\n",
    "        pl_trainer_kwargs={\"callbacks\": [EarlyStopping(monitor=\"val_loss\", patience=3)]},\n",
    "        force_reset=True\n",
    "    )\n",
    "\n",
    "    model.fit(train_target_scaled, future_covariates=train_cov_scaled,\n",
    "              val_series=val_target_scaled, val_future_covariates=val_cov_scaled, verbose=True)\n",
    "\n",
    "    # === Step 10: Forecasting === #\n",
    "    forecast = model.predict(n=output_len, series=val_target_scaled,\n",
    "                             future_covariates=val_cov_scaled, num_samples=100)\n",
    "    forecast_p10 = t_scaler.inverse_transform(forecast.quantile_timeseries(0.1))\n",
    "    forecast_p50 = t_scaler.inverse_transform(forecast.quantile_timeseries(0.5))\n",
    "    forecast_p90 = t_scaler.inverse_transform(forecast.quantile_timeseries(0.9))\n",
    "\n",
    "    # === Step 11: Evaluate === #\n",
    "    actual = val_target.slice_intersect(forecast_p50)\n",
    "    print(f\"[DEBUG] forecast_p50: {forecast_p50.start_time()} to {forecast_p50.end_time()}, len={len(forecast_p50)}\")\n",
    "    print(f\"[DEBUG] actual: {actual.start_time() if len(actual) > 0 else 'N/A'} to {actual.end_time() if len(actual) > 0 else 'N/A'}, len={len(actual)}\")\n",
    "\n",
    "    if len(actual) == 0:\n",
    "        print(f\"[WARNING] Skipping metrics for window {i+1}: No overlapping timestamps.\")\n",
    "        continue\n",
    "\n",
    "    metrics = {\n",
    "        \"Window\": i + 1,\n",
    "        \"MAPE\": mape(actual, forecast_p50),\n",
    "        \"SMAPE\": smape(actual, forecast_p50),\n",
    "        \"MAE\": mae(actual, forecast_p50),\n",
    "        \"RMSE\": rmse(actual, forecast_p50),\n",
    "        \"R2\": r2_score(actual, forecast_p50),\n",
    "        \"MSE\": mse(actual, forecast_p50)\n",
    "    }\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "    # === Step 12: Confidence Interval Plot === #\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.fill_between(forecast_p50.time_index, forecast_p10.values().squeeze(), forecast_p90.values().squeeze(), alpha=0.3, label=\"Confidence Interval\")\n",
    "    forecast_p50.plot(label=\"Forecast (p50)\", color=\"blue\")\n",
    "    actual.plot(label=\"Actual\", color=\"black\")\n",
    "    plt.title(f\"Forecasting Window {i+1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === Step 13: Loss Curve === #\n",
    "    if hasattr(model.trainer, 'callback_metrics'):\n",
    "        loss = model.trainer.callback_metrics\n",
    "        print(f\"[INFO] Final val_loss for window {i+1}: {loss.get('val_loss')}\")\n",
    "\n",
    "# === Step 14: Aggregate Performance === #\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "print(\"\\n[INFO] Aggregated Performance:\")\n",
    "print(metrics_df.describe())\n",
    "\n",
    "# === Step 15: Save Metrics === #\n",
    "metrics_df.to_csv(\"aggregated_window_metrics.csv\", index=False)\n",
    "print(\"[INFO] Saved aggregated metrics to 'aggregated_window_metrics.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
