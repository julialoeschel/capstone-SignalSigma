{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock and Macro Data Processing\n",
    "\n",
    "## Overview\n",
    "This script automates the retrieval, cleansing, and merging of financial stock and macroeconomic data using the `yfinance` API. It processes daily stock prices for top companies and macroeconomic indicators to create a comprehensive dataset for analysis.\n",
    "\n",
    "## Approach\n",
    "1. **Download Stock Data**  \n",
    "   - Retrieve historical price data for selected top stock tickers.\n",
    "   - Clean missing values and rename columns to maintain consistency.\n",
    "\n",
    "2. **Merge Stock Data**  \n",
    "   - Combine individual stock datasets into a unified DataFrame.\n",
    "   - Standardize column names and manage time indices efficiently.\n",
    "\n",
    "3. **Download Macroeconomic Indicators**  \n",
    "   - Collect financial indices, commodity prices, sector ETFs, and cryptocurrencies.\n",
    "   - Handle missing values using forward and backward filling.\n",
    "\n",
    "4. **Final Merge & Export**  \n",
    "   - Merge macroeconomic indicators into the cleaned stock dataset.\n",
    "   - Save the final DataFrame as a CSV file for further analysis.\n",
    "\n",
    "## Key Libraries Used\n",
    "- `yfinance` for financial data retrieval\n",
    "- `pandas` for data manipulation\n",
    "- `matplotlib` & `seaborn` for visualization\n",
    "- `missingno` for missing value diagnostics\n",
    "\n",
    "This ensures a reliable, structured dataset that integrates both stock performance and macroeconomic influences for advanced analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Insights in Stock and Economic Analysis\n",
    "\n",
    "## Stock Prices (`open`, `high`, `low`, `close`)\n",
    "Stock prices represent the value at which a stock is bought or sold during a trading session. These prices help traders and analysts assess market trends, volatility, and investor sentiment.\n",
    "\n",
    "- **Opening Price (`open`)**: The first price at which a stock is traded when the market opens. It reflects overnight investor sentiment and can indicate gaps from previous closing prices.\n",
    "- **Highest Price (`high`)**: The peak price during the trading day. This shows the maximum confidence investors had in the stock.\n",
    "- **Lowest Price (`low`)**: The minimum price during the trading day. It highlights the lowest valuation investors were willing to accept.\n",
    "- **Closing Price (`close`)**: The final price when the market closes. This is often used for trend analysis and is a key metric in stock price movement.\n",
    "\n",
    "### Why These Prices Matter:\n",
    "- Stock prices influence technical indicators such as moving averages, RSI, and Bollinger Bands.\n",
    "- They help investors gauge momentum, trend direction, and possible entry or exit points for trades.\n",
    "\n",
    "---\n",
    "\n",
    "## Trading Volume (`volume`)\n",
    "Trading volume represents the number of shares traded during a given time period. It acts as a measure of investor interest and liquidity in a stock.\n",
    "\n",
    "- **High Volume:** Indicates strong investor participation, often accompanying price changes.\n",
    "- **Low Volume:** Suggests weak investor interest, potentially leading to slower price movements or consolidation.\n",
    "\n",
    "### Importance in Financial Markets:\n",
    "- Volume confirms trends: A rising stock price with high volume suggests strong bullish sentiment.\n",
    "- Sudden spikes in volume may indicate major events like earnings reports or mergers.\n",
    "\n",
    "---\n",
    "\n",
    "## Macro Indicators (e.g., `S&P500_Index`, `Gold_Futures`, `VIX_Index`)\n",
    "Macroeconomic indicators track broader market and economic conditions, providing insights beyond individual stock movements.\n",
    "\n",
    "- **Stock Market Indices (`S&P500_Index`, `NASDAQ_Composite`)**: Represent the performance of major companies and overall investor sentiment.\n",
    "- **Commodity Prices (`Gold_Futures`, `WTI_Oil_Futures`)**: Reflect supply-demand dynamics and inflation trends.\n",
    "- **Volatility Index (`VIX_Index`)**: Measures market fear and uncertainty; a rising VIX indicates higher expected market volatility.\n",
    "\n",
    "### How Macro Indicators Influence Investing:\n",
    "- Investors use macro indicators to predict economic cycles and market trends.\n",
    "- They help in asset allocation strategies, guiding whether to invest in stocks, bonds, or commodities.\n",
    "\n",
    "---\n",
    "\n",
    "## Cryptocurrencies (`BTC-USD`, `ETH-USD`, etc.)\n",
    "Cryptocurrencies represent digital assets operating on decentralized blockchain technology. Their values fluctuate based on market demand, regulation, and technological developments.\n",
    "\n",
    "- **Bitcoin (`BTC-USD`)**: Often referred to as \"digital gold,\" it serves as a store of value.\n",
    "- **Ethereum (`ETH-USD`)**: A blockchain with smart contract capabilities, widely used in decentralized applications.\n",
    "- **Volatility & Investor Sentiment**: Crypto markets tend to be more volatile than traditional assets, offering opportunities and risks.\n",
    "\n",
    "### Role in Financial Markets:\n",
    "- Cryptocurrencies are increasingly used for diversification and hedging against inflation.\n",
    "- Institutions are adopting crypto, impacting stock market correlations and investment strategies.\n",
    "\n",
    "By understanding these financial insights, analysts and investors can make informed decisions regarding asset allocation, risk management, and trading strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL columns BEFORE reset:\n",
      "[('Close', 'AAPL'), ('High', 'AAPL'), ('Low', 'AAPL'), ('Open', 'AAPL'), ('Volume', 'AAPL')]\n",
      "AAPL DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "AAPL final columns: [('Date', ''), ('open_AAPL', 'AAPL'), ('high_AAPL', 'AAPL'), ('low_AAPL', 'AAPL'), ('close_AAPL', 'AAPL'), ('volume_AAPL', 'AAPL')]\n",
      "[✓] AAPL added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT columns BEFORE reset:\n",
      "[('Close', 'MSFT'), ('High', 'MSFT'), ('Low', 'MSFT'), ('Open', 'MSFT'), ('Volume', 'MSFT')]\n",
      "MSFT DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "MSFT final columns: [('Date', ''), ('open_MSFT', 'MSFT'), ('high_MSFT', 'MSFT'), ('low_MSFT', 'MSFT'), ('close_MSFT', 'MSFT'), ('volume_MSFT', 'MSFT')]\n",
      "[✓] MSFT added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGL columns BEFORE reset:\n",
      "[('Close', 'GOOGL'), ('High', 'GOOGL'), ('Low', 'GOOGL'), ('Open', 'GOOGL'), ('Volume', 'GOOGL')]\n",
      "GOOGL DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "GOOGL final columns: [('Date', ''), ('open_GOOGL', 'GOOGL'), ('high_GOOGL', 'GOOGL'), ('low_GOOGL', 'GOOGL'), ('close_GOOGL', 'GOOGL'), ('volume_GOOGL', 'GOOGL')]\n",
      "[✓] GOOGL added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN columns BEFORE reset:\n",
      "[('Close', 'AMZN'), ('High', 'AMZN'), ('Low', 'AMZN'), ('Open', 'AMZN'), ('Volume', 'AMZN')]\n",
      "AMZN DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "AMZN final columns: [('Date', ''), ('open_AMZN', 'AMZN'), ('high_AMZN', 'AMZN'), ('low_AMZN', 'AMZN'), ('close_AMZN', 'AMZN'), ('volume_AMZN', 'AMZN')]\n",
      "[✓] AMZN added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META columns BEFORE reset:\n",
      "[('Close', 'META'), ('High', 'META'), ('Low', 'META'), ('Open', 'META'), ('Volume', 'META')]\n",
      "META DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "META final columns: [('Date', ''), ('open_META', 'META'), ('high_META', 'META'), ('low_META', 'META'), ('close_META', 'META'), ('volume_META', 'META')]\n",
      "[✓] META added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA columns BEFORE reset:\n",
      "[('Close', 'NVDA'), ('High', 'NVDA'), ('Low', 'NVDA'), ('Open', 'NVDA'), ('Volume', 'NVDA')]\n",
      "NVDA DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "NVDA final columns: [('Date', ''), ('open_NVDA', 'NVDA'), ('high_NVDA', 'NVDA'), ('low_NVDA', 'NVDA'), ('close_NVDA', 'NVDA'), ('volume_NVDA', 'NVDA')]\n",
      "[✓] NVDA added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA columns BEFORE reset:\n",
      "[('Close', 'TSLA'), ('High', 'TSLA'), ('Low', 'TSLA'), ('Open', 'TSLA'), ('Volume', 'TSLA')]\n",
      "TSLA DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "TSLA final columns: [('Date', ''), ('open_TSLA', 'TSLA'), ('high_TSLA', 'TSLA'), ('low_TSLA', 'TSLA'), ('close_TSLA', 'TSLA'), ('volume_TSLA', 'TSLA')]\n",
      "[✓] TSLA added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPM columns BEFORE reset:\n",
      "[('Close', 'JPM'), ('High', 'JPM'), ('Low', 'JPM'), ('Open', 'JPM'), ('Volume', 'JPM')]\n",
      "JPM DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "JPM final columns: [('Date', ''), ('open_JPM', 'JPM'), ('high_JPM', 'JPM'), ('low_JPM', 'JPM'), ('close_JPM', 'JPM'), ('volume_JPM', 'JPM')]\n",
      "[✓] JPM added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V columns BEFORE reset:\n",
      "[('Close', 'V'), ('High', 'V'), ('Low', 'V'), ('Open', 'V'), ('Volume', 'V')]\n",
      "V DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "V final columns: [('Date', ''), ('open_V', 'V'), ('high_V', 'V'), ('low_V', 'V'), ('close_V', 'V'), ('volume_V', 'V')]\n",
      "[✓] V added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNJ columns BEFORE reset:\n",
      "[('Close', 'JNJ'), ('High', 'JNJ'), ('Low', 'JNJ'), ('Open', 'JNJ'), ('Volume', 'JNJ')]\n",
      "JNJ DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "JNJ final columns: [('Date', ''), ('open_JNJ', 'JNJ'), ('high_JNJ', 'JNJ'), ('low_JNJ', 'JNJ'), ('close_JNJ', 'JNJ'), ('volume_JNJ', 'JNJ')]\n",
      "[✓] JNJ added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMT columns BEFORE reset:\n",
      "[('Close', 'WMT'), ('High', 'WMT'), ('Low', 'WMT'), ('Open', 'WMT'), ('Volume', 'WMT')]\n",
      "WMT DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "WMT final columns: [('Date', ''), ('open_WMT', 'WMT'), ('high_WMT', 'WMT'), ('low_WMT', 'WMT'), ('close_WMT', 'WMT'), ('volume_WMT', 'WMT')]\n",
      "[✓] WMT added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG columns BEFORE reset:\n",
      "[('Close', 'PG'), ('High', 'PG'), ('Low', 'PG'), ('Open', 'PG'), ('Volume', 'PG')]\n",
      "PG DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "PG final columns: [('Date', ''), ('open_PG', 'PG'), ('high_PG', 'PG'), ('low_PG', 'PG'), ('close_PG', 'PG'), ('volume_PG', 'PG')]\n",
      "[✓] PG added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNH columns BEFORE reset:\n",
      "[('Close', 'UNH'), ('High', 'UNH'), ('Low', 'UNH'), ('Open', 'UNH'), ('Volume', 'UNH')]\n",
      "UNH DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "UNH final columns: [('Date', ''), ('open_UNH', 'UNH'), ('high_UNH', 'UNH'), ('low_UNH', 'UNH'), ('close_UNH', 'UNH'), ('volume_UNH', 'UNH')]\n",
      "[✓] UNH added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIS columns BEFORE reset:\n",
      "[('Close', 'DIS'), ('High', 'DIS'), ('Low', 'DIS'), ('Open', 'DIS'), ('Volume', 'DIS')]\n",
      "DIS DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "DIS final columns: [('Date', ''), ('open_DIS', 'DIS'), ('high_DIS', 'DIS'), ('low_DIS', 'DIS'), ('close_DIS', 'DIS'), ('volume_DIS', 'DIS')]\n",
      "[✓] DIS added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA columns BEFORE reset:\n",
      "[('Close', 'MA'), ('High', 'MA'), ('Low', 'MA'), ('Open', 'MA'), ('Volume', 'MA')]\n",
      "MA DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "MA final columns: [('Date', ''), ('open_MA', 'MA'), ('high_MA', 'MA'), ('low_MA', 'MA'), ('close_MA', 'MA'), ('volume_MA', 'MA')]\n",
      "[✓] MA added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HD columns BEFORE reset:\n",
      "[('Close', 'HD'), ('High', 'HD'), ('Low', 'HD'), ('Open', 'HD'), ('Volume', 'HD')]\n",
      "HD DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "HD final columns: [('Date', ''), ('open_HD', 'HD'), ('high_HD', 'HD'), ('low_HD', 'HD'), ('close_HD', 'HD'), ('volume_HD', 'HD')]\n",
      "[✓] HD added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAC columns BEFORE reset:\n",
      "[('Close', 'BAC'), ('High', 'BAC'), ('Low', 'BAC'), ('Open', 'BAC'), ('Volume', 'BAC')]\n",
      "BAC DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "BAC final columns: [('Date', ''), ('open_BAC', 'BAC'), ('high_BAC', 'BAC'), ('low_BAC', 'BAC'), ('close_BAC', 'BAC'), ('volume_BAC', 'BAC')]\n",
      "[✓] BAC added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFE columns BEFORE reset:\n",
      "[('Close', 'PFE'), ('High', 'PFE'), ('Low', 'PFE'), ('Open', 'PFE'), ('Volume', 'PFE')]\n",
      "PFE DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "PFE final columns: [('Date', ''), ('open_PFE', 'PFE'), ('high_PFE', 'PFE'), ('low_PFE', 'PFE'), ('close_PFE', 'PFE'), ('volume_PFE', 'PFE')]\n",
      "[✓] PFE added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADBE columns BEFORE reset:\n",
      "[('Close', 'ADBE'), ('High', 'ADBE'), ('Low', 'ADBE'), ('Open', 'ADBE'), ('Volume', 'ADBE')]\n",
      "ADBE DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "ADBE final columns: [('Date', ''), ('open_ADBE', 'ADBE'), ('high_ADBE', 'ADBE'), ('low_ADBE', 'ADBE'), ('close_ADBE', 'ADBE'), ('volume_ADBE', 'ADBE')]\n",
      "[✓] ADBE added to merge list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
      "/var/folders/sd/w05frkx11tlgfrfknd40sp740000gn/T/ipykernel_91079/1970253869.py:56: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  merged_df = pd.merge(merged_df, df, on='date', how='outer')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEP columns BEFORE reset:\n",
      "[('Close', 'PEP'), ('High', 'PEP'), ('Low', 'PEP'), ('Open', 'PEP'), ('Volume', 'PEP')]\n",
      "PEP DataFrame shape AFTER dropna and reset_index: (2852, 6)\n",
      "PEP final columns: [('Date', ''), ('open_PEP', 'PEP'), ('high_PEP', 'PEP'), ('low_PEP', 'PEP'), ('close_PEP', 'PEP'), ('volume_PEP', 'PEP')]\n",
      "[✓] PEP added to merge list.\n",
      "\n",
      "=== Merging all DataFrames ===\n",
      "Merging DF 1 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 11)\n",
      "Merging DF 2 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 16)\n",
      "Merging DF 3 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 21)\n",
      "Merging DF 4 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 26)\n",
      "Merging DF 5 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 31)\n",
      "Merging DF 6 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 36)\n",
      "Merging DF 7 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 41)\n",
      "Merging DF 8 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 46)\n",
      "Merging DF 9 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 51)\n",
      "Merging DF 10 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 56)\n",
      "Merging DF 11 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 61)\n",
      "Merging DF 12 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 66)\n",
      "Merging DF 13 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 71)\n",
      "Merging DF 14 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 76)\n",
      "Merging DF 15 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 81)\n",
      "Merging DF 16 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 86)\n",
      "Merging DF 17 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 91)\n",
      "Merging DF 18 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 96)\n",
      "Merging DF 19 with shape (2852, 6)\n",
      "Merged DF shape now: (2852, 101)\n",
      "\n",
      "=== Finalizing merged DataFrame ===\n",
      "\n",
      ":white_check_mark: Final merged DataFrame info:\n",
      "Shape: (2852, 100)\n",
      "Columns: ['open_AAPL', 'high_AAPL', 'low_AAPL', 'close_AAPL', 'volume_AAPL', 'open_MSFT', 'high_MSFT', 'low_MSFT', 'close_MSFT', 'volume_MSFT'] ...\n",
      "Downloading: S&P500_Index (^GSPC)\n",
      "Downloading: Dow_Jones_Index (^DJI)\n",
      "Downloading: NASDAQ_Composite (^IXIC)\n",
      "Downloading: Russell2000_Index (^RUT)\n",
      "Downloading: VIX_Index (^VIX)\n",
      "Downloading: FTSE100_Index (^FTSE)\n",
      "Downloading: Nikkei225_Index (^N225)\n",
      "Downloading: DAX_Index (^GDAXI)\n",
      "Downloading: CAC40_Index (^FCHI)\n",
      "Downloading: HangSeng_Index (^HSI)\n",
      "Downloading: SSE_Composite_Index (000001.SS)\n",
      "Downloading: SZSE_Component_Index (399001.SZ)\n",
      "Downloading: Dollar_Index_DXY (DX-Y.NYB)\n",
      "Downloading: Gold_Futures (GC=F)\n",
      "Downloading: WTI_Oil_Futures (CL=F)\n",
      "Downloading: Copper_Futures (HG=F)\n",
      "Downloading: Brent_Crude_Futures (BZ=F)\n",
      "Downloading: US_Oil_Fund (USO)\n",
      "Downloading: US_Natural_Gas_Fund (UNG)\n",
      "Downloading: SPDR_Gold_Shares (GLD)\n",
      "Downloading: iShares_Silver_Trust (SLV)\n",
      "Downloading: Platinum_Shares_ETF (PPLT)\n",
      "Downloading: Gold_Miners_ETF (GDX)\n",
      "Downloading: Junior_Gold_Miners_ETF (GDXJ)\n",
      "Downloading: RBOB_Gasoline_Futures (XB=F)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['XB=F']: HTTPError('HTTP Error 404: ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: Tech_Sector_ETF (XLK)\n",
      "Downloading: Energy_Sector_ETF (XLE)\n",
      "Downloading: Financial_Sector_ETF (XLF)\n",
      "Downloading: ConsumerDiscretionary_ETF (XLY)\n",
      "Downloading: Lithium_ETF (LIT)\n",
      "Downloading: Semiconductor_ETF (SMH)\n",
      "Downloading: Electricity_Proxy (XLU)\n",
      "Downloading: Healthcare_Sector_ETF (XLV)\n",
      "Downloading: Industrial_Sector_ETF (XLI)\n",
      "Downloading: Materials_Sector_ETF (XLB)\n",
      "Downloading: ConsumerStaples_ETF (XLP)\n",
      "Downloading: Real_Estate_SPDR (XLRE)\n",
      "Downloading: Russell2000_ETF (IWM)\n",
      "Downloading: Nasdaq100_ETF (QQQ)\n",
      "Downloading: Emerging_Markets_ETF (VWO)\n",
      "Downloading: Total_Bond_Market_ETF (BND)\n",
      "Downloading: Real_Estate_Vanguard (VNQ)\n",
      "Downloading: SPDR_Insurance_ETF (KIE)\n",
      "Downloading: Tech_Software_Sector_ETF (IGV)\n",
      "Downloading: ARK_Innovation_ETF (ARKK)\n",
      "Downloading: KBW_Bank_Index (BKX)\n",
      "Downloading: Regional_Banking_ETF (KRE)\n",
      "Downloading: Financials_ETF (VFH)\n",
      "Downloading: 10Y_Treasury_Yield (^TNX)\n",
      "Downloading: 5Y_Treasury_Yield (^FVX)\n",
      "Downloading: 7_10Y_Treasury_ETF (IEF)\n",
      "Downloading: 1_3Y_Treasury_ETF (SHY)\n",
      "Downloading: 20Y_Treasury_ETF (TLT)\n",
      "Downloading: Real_Estate_iShares (IYR)\n",
      "Downloading: Volatility_Index (VIX)\n",
      "Downloading: Personal_Consumption_Expenditures (PCE)\n",
      "Downloading: Bitcoin (BTC-USD)\n",
      "Downloading: Ethereum (ETH-USD)\n",
      "Downloading: XRP (XRP-USD)\n",
      "Downloading: BNB (BNB-USD)\n",
      "Downloading: Solana (SOL-USD)\n",
      "Downloading: Dogecoin (DOGE-USD)\n",
      "Downloading: Cardano (ADA-USD)\n",
      "Downloading: TRON (TRX-USD)\n",
      "Downloading: Avalanche (AVAX-USD)\n",
      "Downloading: Chainlink (LINK-USD)\n",
      "Downloading: Stellar (XLM-USD)\n",
      "Downloading: Uniswap (UNI-USD)\n",
      "Downloading: Bitcoin_Cash (BCH-USD)\n",
      "Downloading: Polygon (MATIC-USD)\n",
      "Downloading: Litecoin (LTC-USD)\n",
      "Downloading: Cosmos_Hub (ATOM-USD)\n",
      "Downloading: Ethereum_Classic (ETC-USD)\n",
      "Downloading: Monero (XMR-USD)\n",
      "Downloading: Algorand (ALGO-USD)\n",
      "Downloading: VeChain (VET-USD)\n",
      "Downloading: Filecoin (FIL-USD)\n",
      "Downloading: Internet_Computer (ICP-USD)\n",
      "Downloading: Hedera (HBAR-USD)\n",
      "Downloading: NEAR_Protocol (NEAR-USD)\n",
      "Downloading: Aave (AAVE-USD)\n",
      "Downloading: EOS (EOS-USD)\n",
      ":white_check_mark: Finished loading macro data.\n",
      ":mag: Null values remaining: 0\n",
      ":white_check_mark: Saved full macro data to 'clean_stock_data_with_time_index.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Import Required Libraries ---\n",
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import holidays\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# --- Download Configuration ---\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2025-05-6\"\n",
    "# Define list of top stock tickers\n",
    "tickers = [\n",
    "    \"AAPL\",\n",
    "    \"MSFT\",\n",
    "    \"GOOGL\",\n",
    "    \"AMZN\",\n",
    "    \"META\",\n",
    "    \"NVDA\",\n",
    "    \"TSLA\",\n",
    "    \"JPM\",\n",
    "    \"V\",\n",
    "    \"JNJ\",\n",
    "    \"WMT\",\n",
    "    \"PG\",\n",
    "    \"UNH\",\n",
    "    \"DIS\",\n",
    "    \"MA\",\n",
    "    \"HD\",\n",
    "    \"BAC\",\n",
    "    \"PFE\",\n",
    "    \"ADBE\",\n",
    "    \"PEP\",\n",
    "]\n",
    "# List to collect all individual DataFrames\n",
    "all_dfs = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # print(f\"\\n=== Downloading {ticker} ===\")\n",
    "        df = yf.download(\n",
    "            ticker, start=start_date, end=end_date, interval=\"1d\", progress=True\n",
    "        )\n",
    "        print(f\"{ticker} columns BEFORE reset:\\n{df.columns.tolist()}\")\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        print(f\"{ticker} DataFrame shape AFTER dropna and reset_index: {df.shape}\")\n",
    "        # Map column names to include ticker\n",
    "        column_map = {\n",
    "            \"Open\": f\"open_{ticker}\",\n",
    "            \"High\": f\"high_{ticker}\",\n",
    "            \"Low\": f\"low_{ticker}\",\n",
    "            \"Close\": f\"close_{ticker}\",\n",
    "            \"Adj Close\": f\"adj_close_{ticker}\",\n",
    "            \"Volume\": f\"volume_{ticker}\",\n",
    "        }\n",
    "        # Only rename columns that exist\n",
    "        existing_rename_map = {k: v for k, v in column_map.items() if k in df.columns}\n",
    "        df.rename(columns=existing_rename_map, inplace=True)\n",
    "        # Keep only Date and renamed columns\n",
    "        columns_to_keep = [\"Date\"] + list(existing_rename_map.values())\n",
    "        df = df[columns_to_keep]\n",
    "        print(f\"{ticker} final columns: {df.columns.tolist()}\")\n",
    "        all_dfs.append(df)\n",
    "        print(f\"[✓] {ticker} added to merge list.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[✗] Error downloading {ticker}: {e}\")\n",
    "# Check if any data was downloaded\n",
    "if not all_dfs:\n",
    "    raise RuntimeError(\"No stock data was successfully downloaded.\")\n",
    "# === Merge all DataFrames ===\n",
    "print(\"\\n=== Merging all DataFrames ===\")\n",
    "merged_df = all_dfs[0].rename(columns={\"Date\": \"date\"})\n",
    "for i, df in enumerate(all_dfs[1:], start=1):\n",
    "    df.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "    print(f\"Merging DF {i} with shape {df.shape}\")\n",
    "    merged_df = pd.merge(merged_df, df, on=\"date\", how=\"outer\")\n",
    "    print(f\"Merged DF shape now: {merged_df.shape}\")\n",
    "# Set 'date' as datetime index\n",
    "print(\"\\n=== Finalizing merged DataFrame ===\")\n",
    "merged_df[\"date\"] = pd.to_datetime(merged_df[\"date\"])\n",
    "merged_df.set_index(\"date\", inplace=True)\n",
    "merged_df.sort_index(inplace=True)\n",
    "# Clean up column names if MultiIndex\n",
    "if isinstance(merged_df.columns, pd.MultiIndex):\n",
    "    merged_df.columns = [\n",
    "        \"_\".join(filter(None, col)).strip() for col in merged_df.columns\n",
    "    ]\n",
    "# Remove duplicated ticker names (e.g., open_AAPL_AAPL)\n",
    "merged_df.columns = [col.replace(\"__\", \"_\") for col in merged_df.columns]\n",
    "merged_df.columns = [\n",
    "    \"_\".join(dict.fromkeys(col.split(\"_\"))) if \"_\" in col else col\n",
    "    for col in merged_df.columns\n",
    "]\n",
    "merged_df.index.name = \"date\"\n",
    "clean_stock_data_df = merged_df.copy()\n",
    "# Final debug print\n",
    "print(\"\\n:white_check_mark: Final merged DataFrame info:\")\n",
    "print(f\"Shape: {clean_stock_data_df.shape}\")\n",
    "print(f\"Columns: {clean_stock_data_df.columns.tolist()[:10]} ...\")\n",
    "clean_stock_data_df.head(10)\n",
    "# --- Define Macro Tickers and Labels ---\n",
    "macro_tickers = {\n",
    "    # Indices\n",
    "    \"^GSPC\": \"S&P500_Index\",\n",
    "    \"^DJI\": \"Dow_Jones_Index\",\n",
    "    \"^IXIC\": \"NASDAQ_Composite\",\n",
    "    \"^RUT\": \"Russell2000_Index\",\n",
    "    \"^VIX\": \"VIX_Index\",\n",
    "    \"^FTSE\": \"FTSE100_Index\",\n",
    "    \"^N225\": \"Nikkei225_Index\",\n",
    "    \"^GDAXI\": \"DAX_Index\",\n",
    "    \"^FCHI\": \"CAC40_Index\",\n",
    "    \"^HSI\": \"HangSeng_Index\",\n",
    "    \"000001.SS\": \"SSE_Composite_Index\",\n",
    "    \"399001.SZ\": \"SZSE_Component_Index\",\n",
    "    # Commodities & Funds\n",
    "    \"DX-Y.NYB\": \"Dollar_Index_DXY\",\n",
    "    \"GC=F\": \"Gold_Futures\",\n",
    "    \"CL=F\": \"WTI_Oil_Futures\",\n",
    "    \"HG=F\": \"Copper_Futures\",\n",
    "    \"BZ=F\": \"Brent_Crude_Futures\",\n",
    "    \"USO\": \"US_Oil_Fund\",\n",
    "    \"UNG\": \"US_Natural_Gas_Fund\",\n",
    "    \"GLD\": \"SPDR_Gold_Shares\",\n",
    "    \"SLV\": \"iShares_Silver_Trust\",\n",
    "    \"PPLT\": \"Platinum_Shares_ETF\",\n",
    "    \"GDX\": \"Gold_Miners_ETF\",\n",
    "    \"GDXJ\": \"Junior_Gold_Miners_ETF\",\n",
    "    \"XB=F\": \"RBOB_Gasoline_Futures\",\n",
    "    # Sector ETFs\n",
    "    \"XLK\": \"Tech_Sector_ETF\",\n",
    "    \"XLE\": \"Energy_Sector_ETF\",\n",
    "    \"XLF\": \"Financial_Sector_ETF\",\n",
    "    \"XLY\": \"ConsumerDiscretionary_ETF\",\n",
    "    \"LIT\": \"Lithium_ETF\",\n",
    "    \"SMH\": \"Semiconductor_ETF\",\n",
    "    \"XLU\": \"Electricity_Proxy\",\n",
    "    \"XLV\": \"Healthcare_Sector_ETF\",\n",
    "    \"XLI\": \"Industrial_Sector_ETF\",\n",
    "    \"XLB\": \"Materials_Sector_ETF\",\n",
    "    \"XLP\": \"ConsumerStaples_ETF\",\n",
    "    \"XLRE\": \"Real_Estate_SPDR\",\n",
    "    \"IWM\": \"Russell2000_ETF\",\n",
    "    \"QQQ\": \"Nasdaq100_ETF\",\n",
    "    \"VWO\": \"Emerging_Markets_ETF\",\n",
    "    \"BND\": \"Total_Bond_Market_ETF\",\n",
    "    \"VNQ\": \"Real_Estate_Vanguard\",\n",
    "    \"KIE\": \"SPDR_Insurance_ETF\",\n",
    "    \"IGV\": \"Tech_Software_Sector_ETF\",\n",
    "    \"ARKK\": \"ARK_Innovation_ETF\",\n",
    "    # Financial Indices & Treasury\n",
    "    \"BKX\": \"KBW_Bank_Index\",\n",
    "    \"KRE\": \"Regional_Banking_ETF\",\n",
    "    \"VFH\": \"Financials_ETF\",\n",
    "    \"^TNX\": \"10Y_Treasury_Yield\",\n",
    "    \"^FVX\": \"5Y_Treasury_Yield\",\n",
    "    \"IEF\": \"7_10Y_Treasury_ETF\",\n",
    "    \"SHY\": \"1_3Y_Treasury_ETF\",\n",
    "    \"TLT\": \"20Y_Treasury_ETF\",\n",
    "    \"IYR\": \"Real_Estate_iShares\",\n",
    "    # Risk & Sentiment\n",
    "    \"VIX\": \"Volatility_Index\",\n",
    "    \"PCE\": \"Personal_Consumption_Expenditures\",\n",
    "    # Cryptocurrencies\n",
    "    \"BTC-USD\": \"Bitcoin\",\n",
    "    \"ETH-USD\": \"Ethereum\",\n",
    "    \"XRP-USD\": \"XRP\",\n",
    "    \"BNB-USD\": \"BNB\",\n",
    "    \"SOL-USD\": \"Solana\",\n",
    "    \"DOGE-USD\": \"Dogecoin\",\n",
    "    \"ADA-USD\": \"Cardano\",\n",
    "    \"TRX-USD\": \"TRON\",\n",
    "    \"AVAX-USD\": \"Avalanche\",\n",
    "    \"LINK-USD\": \"Chainlink\",\n",
    "    \"XLM-USD\": \"Stellar\",\n",
    "    \"UNI-USD\": \"Uniswap\",\n",
    "    \"BCH-USD\": \"Bitcoin_Cash\",\n",
    "    \"MATIC-USD\": \"Polygon\",\n",
    "    \"LTC-USD\": \"Litecoin\",\n",
    "    \"ATOM-USD\": \"Cosmos_Hub\",\n",
    "    \"ETC-USD\": \"Ethereum_Classic\",\n",
    "    \"XMR-USD\": \"Monero\",\n",
    "    \"ALGO-USD\": \"Algorand\",\n",
    "    \"VET-USD\": \"VeChain\",\n",
    "    \"FIL-USD\": \"Filecoin\",\n",
    "    \"ICP-USD\": \"Internet_Computer\",\n",
    "    \"HBAR-USD\": \"Hedera\",\n",
    "    \"NEAR-USD\": \"NEAR_Protocol\",\n",
    "    \"AAVE-USD\": \"Aave\",\n",
    "    \"EOS-USD\": \"EOS\",\n",
    "}\n",
    "# --- Download Data ---\n",
    "macro_df = pd.DataFrame()\n",
    "for ticker, label in macro_tickers.items():\n",
    "    print(f\"Downloading: {label} ({ticker})\")\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        macro_df[label] = df[\"Close\"]\n",
    "    except Exception as e:\n",
    "        print(f\":x: Error downloading {label}: {e}\")\n",
    "# --- Data Cleaning ---\n",
    "macro_df.dropna(axis=1, how=\"all\", inplace=True)  # Drop fully missing columns\n",
    "macro_df.ffill(inplace=True)  # Forward fill (macroeconomic data is slower to update)\n",
    "macro_df.bfill(inplace=True)  # Backward fill (to handle early missing data)\n",
    "macro_df.index.name = \"date\"\n",
    "# --- Diagnostics ---\n",
    "print(\":white_check_mark: Finished loading macro data.\")\n",
    "print(\":mag: Null values remaining:\", macro_df.isnull().sum().sum())\n",
    "# :pushpin: Merge macroeconomic indicators into your cleaned stock dataset\n",
    "# Assumes both DataFrames use datetime as index\n",
    "clean_stock_data_df = clean_stock_data_df.merge(\n",
    "    macro_df, left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "# Save to CSV\n",
    "# Assuming 'clean_stock_data_df' is your DataFrame with 'date' as index\n",
    "path_stock = \"../data/Stock_market_data\"\n",
    "clean_stock_data_df.to_csv(\n",
    "    f\"{path_stock}/clean_stock_data_with_time_index.csv\",\n",
    "    index=True,\n",
    "    date_format=\"%Y-%m-%d\",\n",
    ")\n",
    "print(\n",
    "    \":white_check_mark: Saved full macro data to 'clean_stock_data_with_time_index.csv'\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
